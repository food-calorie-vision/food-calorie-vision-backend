import json
import re
import uuid
from datetime import datetime
from functools import lru_cache
from typing import Any, Dict, Optional

from fastapi import APIRouter, BackgroundTasks, Depends, HTTPException, status
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from app.api.dependencies import get_current_active_user
from app.api.v1.schemas.chat import ChatMessageRequest, ChatMessageResponse
from app.core.config import get_settings
from app.db.models import ChatHistory, Conversation, User
from app.db.redis_session import get_redis_client
from app.db.session import get_session
from app.services.chat_service import ChatService
from app.services.langchain_agent import AgentContext, get_langchain_agent_factory
from app.services.recipe_recommendation_service import get_recipe_recommendation_service
from app.services.user_context_cache import get_or_build_user_context, refresh_user_context

router = APIRouter(prefix="/chat", tags=["Chat"])

settings = get_settings()


@lru_cache
def get_clarify_llm() -> ChatOpenAI:
    if not settings.openai_api_key:
        raise HTTPException(status_code=500, detail="OPENAI_API_KEY is not configured.")
    return ChatOpenAI(
        api_key=settings.openai_api_key,
        model="gpt-4o-mini",
        temperature=0.4,
        model_kwargs={"response_format": {"type": "json_object"}},
    )


CLARIFY_CONFIRMATION_MESSAGE = "ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ì§„í–‰ì„ ì›í•˜ì‹œë©´ 'ë„¤' ë˜ëŠ” 'ì‘'ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”."

RECIPE_NEGATION_KEYWORDS = [
    "ë ˆì‹œí”¼ ë§ê³ ",
    "ë ˆì‹œí”¼ í•„ìš” ì—†ì–´",
    "ë ˆì‹œí”¼ í•„ìš”ì—†ì–´",
    "ì•„ë‹ˆ",
    "ì•„ë‹ˆìš”",
    "ì•„ë‹ˆì˜¤",
    "ì‹«ì–´",
    "ëì–´",
    "ê´œì°®ì•„",
]


RECIPE_REQUEST_PATTERNS = [
    re.compile(
        r"(ë ˆì‹œí”¼|ì¡°ë¦¬ë²•|ìš”ë¦¬ë²•|ë§Œë“œëŠ”\s?ë²•|ë§Œë“œëŠ”\s?ë°©ë²•).*(ì•Œë ¤|ì¶”ì²œ|ë³´ì—¬|ì°¾ì•„|ì¤„|í•´ì¤˜|ë¶€íƒ|ê°€ëŠ¥|ê°€ë¥´ì³)"
    ),
    re.compile(
        r"(ì•Œë ¤|ì¶”ì²œ|ë³´ì—¬|ì°¾ì•„|ì¤„|í•´ì¤˜|ë¶€íƒ|ê°€ëŠ¥|ê°€ë¥´ì³).*(ë ˆì‹œí”¼|ì¡°ë¦¬ë²•|ìš”ë¦¬ë²•|ë§Œë“œëŠ”\s?ë²•|ë§Œë“œëŠ”\s?ë°©ë²•)"
    ),
    re.compile(r"(ì–´ë–»ê²Œ|ë°©ë²•).*(ë§Œë“¤|ìš”ë¦¬í•´)"),
    re.compile(r"(ë ˆì‹œí”¼|ì¡°ë¦¬ë²•|ë§Œë“œëŠ”\s?ë²•).*(ì¶”ì²œí•´ì¤˜|ì•Œë ¤ì¤˜|ë³´ì—¬ì¤˜|ì°¾ì•„ì¤˜)"),
]


def _log_recipe_debug(event: str, extra: Optional[Dict[str, Any]] = None) -> None:
    payload: Dict[str, Any] = {
        "event": event,
        "ts": datetime.utcnow().isoformat(),
    }
    if extra:
        payload.update(extra)
    try:
        serialized = json.dumps(payload, ensure_ascii=False)
    except TypeError:
        serialized = str(payload)
    print(f"ğŸ§© [RecipeConfirm] {serialized}")


CLARIFY_PROMPT = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """ë„ˆëŠ” ì¹œê·¼í•œ í•œêµ­ì–´ ì˜ì–‘ì‚¬ ì±—ë´‡ì´ì•¼.
- ìµœê·¼ ëŒ€í™” ìš”ì•½: {summary}
- í•­ìƒ JSON ê°ì²´ë§Œ ì¶œë ¥í•´ì•¼ í•´. í•„ë“œëŠ” response_id, action_type, message, suggestions, needs_tool_call.
- ì‚¬ìš©ìê°€ ì¡ë‹´ì´ë‚˜ ì˜ì–‘/ê±´ê°• ê´€ë ¨ ì§ˆë¬¸ì„ í•˜ë©´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µí•˜ê³ , í•„ìš”í•œ ê²½ìš° ë¶€ë“œëŸ½ê²Œ ì¶”ê°€ ì •ë³´ë¥¼ ë¬¼ì–´ë´.
- ì‚¬ìš©ìê°€ â€œì•„ë‹ˆâ€, â€œì‹«ì–´â€ ë“± ë¶€ì • í‘œí˜„ì„ ì“°ë©´ needs_tool_callì€ falseë¡œ ìœ ì§€í•˜ê³  ëŒ€í™”í˜• í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µí•´.
- "ë ˆì‹œí”¼ ì¶”ì²œí•´ì¤˜", "ë§Œë“œëŠ” ë²• ì•Œë ¤ì¤˜", "~ ì–´ë–»ê²Œ ë§Œë“¤ì–´?"ì²˜ëŸ¼ ëª…í™•í•˜ê²Œ ì¶”ì²œ/ì¡°ë¦¬ë²•ì„ ìš”ì²­í•  ë•Œë§Œ needs_tool_callì„ trueë¡œ í•˜ê³ , messageì— í™•ì¸ ë¬¸êµ¬ë¥¼ ë„£ì–´.
- needs_tool_callì´ trueì¼ ë•Œë§Œ messageì— "ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ì§„í–‰ì„ ì›í•˜ì‹œë©´ 'ë„¤' ë˜ëŠ” 'ì‘'ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”."ë¥¼ í¬í•¨í•´.
- needs_tool_callì´ falseì¼ ë•ŒëŠ” í™•ì¸ ë¬¸êµ¬ë‚˜ ê³¼í•œ ì¶”ê°€ ì§ˆë¬¸ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”/ì§ˆë¬¸/ì •ë³´ë§Œ messageì— ë‹´ì•„.
- ëª¨í˜¸í•œ ì§ˆë¬¸ì´ë‚˜ ì •ë³´ íƒìƒ‰, ë¶€ì • í‘œí˜„ì€ needs_tool_call=falseë¡œ ìœ ì§€í•´.
- suggestionsì—ëŠ” ì‚¬ìš©ìê°€ ë°”ë¡œ í´ë¦­í•´ì„œ ë³´ë‚¼ ìˆ˜ ìˆëŠ” ì§§ì€ ë°œí™” ì˜ˆì‹œ 2~3ê°œ(ì˜ˆ: "ë§¤ì½¤í•œ ë ˆì‹œí”¼ ì¶”ì²œí•´ì¤˜", "ë‹¤ë¥¸ ì§ˆë¬¸ ìˆì–´")ë§Œ ë„£ì–´. ì±—ë´‡ì´ ë˜ì§€ëŠ” ì§ˆë¬¸ì€ messageì—ë§Œ ë„£ì–´.
- action_typeì€ í•­ìƒ TEXT_ONLYë¡œ ê³ ì •í•´.
""",
        ),
        ("human", "{user_message}"),
    ]
)


def _normalize_text_for_intent(text: str) -> str:
    return (text or "").strip().lower()


def _matches_recipe_request(text: str) -> bool:
    normalized = _normalize_text_for_intent(text)
    if not normalized:
        return False
    return any(pattern.search(normalized) for pattern in RECIPE_REQUEST_PATTERNS)


def _evaluate_recipe_intent_flags(user_message: str) -> tuple[bool, bool]:
    normalized = _normalize_text_for_intent(user_message)
    if not normalized:
        return False, False
    has_negation = any(keyword in normalized for keyword in RECIPE_NEGATION_KEYWORDS)
    if has_negation:
        return False, True
    has_recipe_request = _matches_recipe_request(normalized)
    return has_recipe_request, False


async def _generate_clarify_payload(summary: str, user_message: str) -> dict:
    clarify_llm = get_clarify_llm()
    messages = CLARIFY_PROMPT.format_messages(
        summary=summary or "ì´ì „ ëŒ€í™” ì—†ìŒ",
        user_message=user_message,
    )
    try:
        response = await clarify_llm.ainvoke(messages)
        payload = json.loads(response.content)
    except Exception:
        payload = {}

    payload.setdefault("response_id", f"clarify-{uuid.uuid4()}")
    payload.setdefault("action_type", "TEXT_ONLY")
    payload.setdefault("message", "ì‚¬ìš©ìë‹˜ì˜ ìš”ì²­ì„ ì´í•´í–ˆì–´ìš”. ë” ìì„¸íˆ ë§ì”€í•´ì£¼ì‹¤ê¹Œìš”?")
    suggestions = payload.get("suggestions")
    if not isinstance(suggestions, list) or len(suggestions) == 0:
        payload["suggestions"] = ["ë ˆì‹œí”¼ ì¶”ì²œí•´ì¤˜", "ë‹¤ë¥¸ ì§ˆë¬¸ ìˆì–´"]
    payload.setdefault("needs_tool_call", False)
    return payload


@router.get("/context")
async def refresh_chat_context(
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_session),
):
    """Recommend íƒ­ ì§„ì… ì‹œ ìµœì‹  ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°•ì œë¡œ ê°±ì‹ ."""
    ctx = await refresh_user_context(db, current_user.user_id)
    return {
        "success": True,
        "message": "ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒˆë¡œê³ ì¹¨í–ˆìŠµë‹ˆë‹¤.",
        "data": {
            "diseases": ctx.diseases,
            "allergies": ctx.allergies,
            "has_eaten_today": ctx.has_eaten_today,
            "last_refreshed": ctx.last_refreshed.isoformat(),
        },
    }


@router.post("/prewarm")
async def prewarm_chat_agent(
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_session),
) -> dict:
    """Recommend íƒ­ ì§„ì… ì§í›„ AIê°€ ê¸°ë³¸ ì •ë³´ë¥¼ ì½ì–´ë“¤ì´ë„ë¡ ì›Œë°ì—…."""
    cached_context = await get_or_build_user_context(db, current_user.user_id)
    conversation = await db.get(Conversation, f"prewarm-{current_user.user_id}")
    agent_context = AgentContext(
        user=current_user,
        session=db,
        conversation_summary=conversation.sum_chat if conversation else None,
        diseases=cached_context.diseases,
        allergies=cached_context.allergies,
        has_eaten_today=cached_context.has_eaten_today,
    )
    agent_factory = get_langchain_agent_factory()
    agent_executor = await agent_factory.create_executor(context=agent_context)
    await agent_executor.ainvoke({"input": "ì‚¬ìš©ì ì •ë³´ë¥¼ ì¤€ë¹„í•˜ê³  ë‹¤ìŒ ì§ˆë¬¸ì„ ë°›ì„ ì¤€ë¹„ë¥¼ í•˜ì„¸ìš”."})
    return {"success": True, "message": "ì—ì´ì „íŠ¸ ì›Œë°ì—… ì™„ë£Œ"}


@router.post("/", response_model=ChatMessageResponse)
async def handle_chat_message(
    request: ChatMessageRequest,
    background_tasks: BackgroundTasks,
    current_user: User = Depends(get_current_active_user),
    db: AsyncSession = Depends(get_session),
    redis_client = Depends(get_redis_client),
):
    """
    Handles incoming chat messages from users.
    - Manages conversation sessions and triggers summarization.
    - Gets a response from the LangChain agent.
    - Saves conversation history.
    """
    chat_service = ChatService(redis_client=redis_client, db_session=db)

    previous_session_id = await chat_service.get_previous_session_id_and_update(
        user_id=current_user.user_id, current_session_id=request.session_id
    )

    if previous_session_id and previous_session_id != request.session_id:
        background_tasks.add_task(
            chat_service.summarize_conversation_if_needed, previous_session_id
        )

    cached_context = await get_or_build_user_context(db, current_user.user_id)
    diseases = cached_context.diseases
    allergies = cached_context.allergies
    has_eaten_today = cached_context.has_eaten_today
    recipe_service = get_recipe_recommendation_service()

    conversation = await db.get(Conversation, request.session_id)
    is_new_conversation = conversation is None

    conversation_summary = ""
    if is_new_conversation:
        summary_stmt = (
            select(Conversation.sum_chat)
            .where(
                Conversation.user_id == current_user.user_id,
                Conversation.sum_chat.isnot(None),
            )
            .order_by(Conversation.last_message_summarized_at.desc())
            .limit(1)
        )
        summary_result = await db.execute(summary_stmt)
        latest_summary = summary_result.scalar_one_or_none()
        if latest_summary:
            conversation_summary = latest_summary
    elif conversation and conversation.sum_chat:
        conversation_summary = conversation.sum_chat

    agent_context = AgentContext(
        user=current_user,
        session=db,
        conversation_summary=conversation_summary,
        diseases=diseases,
        allergies=allergies,
        has_eaten_today=has_eaten_today,
    )

    mode = (request.mode or "clarify").lower()
    ai_response_payload: str
    display_text: str
    needs_tool_call_flag = False

    def _normalize_agent_output(raw_text: str) -> tuple[str, str]:
        """ensure frontend always receives valid JSON payload"""
        safe_text = (raw_text or "").strip()
        if not safe_text:
            safe_text = "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ë§Œë“¤ì§€ ëª»í–ˆì–´ìš”."
        try:
            json.loads(safe_text)
            return safe_text, safe_text
        except json.JSONDecodeError:
            fallback = {
                "response_id": f"fallback-{uuid.uuid4()}",
                "action_type": "TEXT_ONLY",
                "message": safe_text,
                "suggestions": ["ë‹¤ì‹œ ì‹œë„í• ë˜", "ë‹¤ë¥¸ ì§ˆë¬¸ í• ê²Œ"],
                "data": None,
            }
            return json.dumps(fallback, ensure_ascii=False), safe_text

    async def _build_recipe_fallback_response() -> tuple[str, str] | None:
        try:
            if len(request.message.strip()) < 4:
                fallback_payload = {
                    "response_id": f"clarify-{uuid.uuid4()}",
                    "action_type": "TEXT_ONLY",
                    "message": (
                        "ì–´ë–¤ ë ˆì‹œí”¼ê°€ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ì‹ì¬ë£Œë‚˜ ë¼ë‹ˆë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë„ì™€ë“œë¦´ê²Œìš”.\n"
                        "ì¶”ì²œì„ ì›í•˜ì‹œë©´ 'ë„¤' ë˜ëŠ” 'ì‘'ì´ë¼ê³  ë‹µí•´ì£¼ì„¸ìš”."
                    ),
                    "suggestions": ["ë‹­ê°€ìŠ´ì‚´ ìš”ë¦¬ ì•Œë ¤ì¤˜", "ì•„ì¹¨ ë©”ë‰´ ì¶”ì²œí•´ì¤˜"],
                    "data": None,
                }
                return json.dumps(fallback_payload, ensure_ascii=False), fallback_payload["message"]

            recipe_service = get_recipe_recommendation_service()
            fallback = await recipe_service.get_recipe_recommendations(
                user=current_user,
                user_request=request.message,
                diseases=diseases,
                allergies=allergies,
                has_eaten_today=has_eaten_today,
            )
            response_payload = {
                "response_id": f"fallback-{uuid.uuid4()}",
                "action_type": "RECOMMENDATION_RESULT",
                "message": fallback.get("user_friendly_message") or "ë ˆì‹œí”¼ë¥¼ ì°¾ì•„ë´¤ì–´ìš”!",
                "data": {
                    "recipes": fallback.get("recommendations"),
                    "health_warning": fallback.get("health_warning"),
                    "inferred_preference": fallback.get("inferred_preference"),
                    "user_friendly_message": fallback.get("user_friendly_message"),
                },
                "suggestions": ["ì¬ë£Œ í™•ì¸í•´ì¤˜", "ë‹¤ë¥¸ ë©”ë‰´ ì¶”ì²œí•´ì¤˜"],
            }
            return json.dumps(response_payload, ensure_ascii=False), response_payload["message"]
        except Exception as exc:  # pragma: no cover
            print(f"âš ï¸ ë ˆì‹œí”¼ í´ë°± ìƒì„± ì‹¤íŒ¨: {exc}")
            return None

    if mode == "clarify":
        force_tool_call, force_tool_block = _evaluate_recipe_intent_flags(request.message)
        clarify_payload = await _generate_clarify_payload(conversation_summary, request.message)

        if force_tool_block:
            clarify_payload["needs_tool_call"] = False
            message_text = clarify_payload.get("message", "")
            if CLARIFY_CONFIRMATION_MESSAGE in message_text:
                clarify_payload["message"] = "ì•Œê² ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìš”ì²­ì´ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
        elif force_tool_call:
            clarify_payload["needs_tool_call"] = True
            clarify_payload["message"] = CLARIFY_CONFIRMATION_MESSAGE

        needs_tool_call_flag = bool(clarify_payload.get("needs_tool_call"))
        ai_response_payload = json.dumps(clarify_payload, ensure_ascii=False)
        display_text = clarify_payload.get("message", "")
    else:
        safety_mode = (request.safety_mode or "").lower()
        quick_confirmation_payload: Optional[Dict[str, Any]] = None
        if safety_mode not in {"proceed", "health_first"}:
            quick_analysis = await recipe_service.quick_analyze_intent(
                user=current_user,
                intent_text=request.message,
                diseases=diseases,
                allergies=allergies,
                has_eaten_today=has_eaten_today,
            )
            disease_conflict = bool(quick_analysis.get("disease_conflict"))
            allergy_conflict = bool(quick_analysis.get("allergy_conflict"))
            _log_recipe_debug(
                "HealthCheck",
                {
                    "session_id": request.session_id,
                    "user_id": current_user.user_id,
                    "disease_conflict": disease_conflict,
                    "allergy_conflict": allergy_conflict,
                    "diseases": diseases or [],
                    "allergies": allergies or [],
                },
            )
            requires_confirmation = disease_conflict or allergy_conflict
            if requires_confirmation:
                disease_text = ", ".join(diseases or []) or "ì—†ìŒ"
                allergy_text = ", ".join(allergies or []) or "ì—†ìŒ"
                conflict_lines = []
                if disease_conflict:
                    conflict_lines.append(f"ë“±ë¡ëœ ì§ˆë³‘({disease_text})ê³¼ ìš”ì²­í•œ ë©”ë‰´ê°€ ì¶©ëŒí•  ìˆ˜ ìˆì–´ìš”.")
                if allergy_conflict:
                    conflict_lines.append(f"ì•Œë ˆë¥´ê¸° ëª©ë¡({allergy_text})ì— í¬í•¨ëœ ì¬ë£Œê°€ ìˆì–´ìš”.")
                combined_warning = quick_analysis.get("health_warning") or "\n".join(conflict_lines)
                confirm_message = (
                    f"{quick_analysis.get('user_message') or 'ê±´ê°•ì„ ê³ ë ¤í•´ë³¼ê¹Œìš”?'}\n\n"
                    f"{combined_warning}\n\n"
                    "ê±´ê°•ì„ ìš°ì„ í•´ì„œ ë ˆì‹œí”¼ë¥¼ ì¡°ì •í• ê¹Œìš”, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ì§„í–‰í• ê¹Œìš”?"
                )
                quick_confirmation_payload = {
                    "response_id": f"health-{uuid.uuid4()}",
                    "action_type": "HEALTH_CONFIRMATION",
                    "message": confirm_message,
                    "data": {
                        "health_warning": combined_warning,
                        "user_friendly_message": quick_analysis.get("user_message"),
                    },
                    "suggestions": ["ê·¸ëŒ€ë¡œ ì§„í–‰í•´ì¤˜", "ê±´ê°•í•˜ê²Œ ë°”ê¿”ì¤˜"],
                }
            else:
                _log_recipe_debug(
                    "HealthCheckNoConflict",
                    {
                        "session_id": request.session_id,
                        "user_id": current_user.user_id,
                        "diseases": diseases or [],
                        "allergies": allergies or [],
                    },
                )

        if quick_confirmation_payload:
            ai_response_payload = json.dumps(quick_confirmation_payload, ensure_ascii=False)
            display_text = quick_confirmation_payload["message"]
        else:
            _log_recipe_debug(
                "ExecuteModeEntered",
                {
                "session_id": request.session_id,
                "user_id": current_user.user_id,
                "message_preview": request.message[:120],
                "diseases_count": len(diseases or []),
                "allergies_count": len(allergies or []),
                "has_eaten_today": has_eaten_today,
            },
        )
            agent_factory = get_langchain_agent_factory()
            _log_recipe_debug("LangChainAgentFactoryReady", {"session_id": request.session_id})
            agent_executor = await agent_factory.create_executor(context=agent_context)
            _log_recipe_debug(
                "LangChainAgentExecutorReady",
                {"session_id": request.session_id},
            )

            agent_input = request.message
            if safety_mode == "proceed":
                agent_input += "\n\n[ì‚¬ìš©ì ì„ íƒ] ê±´ê°• ê²½ê³ ë¥¼ ì¸ì§€í–ˆì§€ë§Œ ì›ë˜ ìš”ì²­ ê·¸ëŒ€ë¡œ ì§„í–‰í•´ë„ ê´œì°®ìŠµë‹ˆë‹¤."
            elif safety_mode == "health_first":
                agent_input += "\n\n[ì‚¬ìš©ì ì„ íƒ] ê±´ê°•ì„ ìš°ì„ í•˜ë‹ˆ ì €ì—¼/ì €ì§€ë°© ëŒ€ì²´ ë ˆì‹œí”¼ë¥¼ ìš°ì„  ì¶”ì²œí•´ì£¼ì„¸ìš”."

            ai_response = await agent_executor.ainvoke({"input": agent_input})
            _log_recipe_debug(
                "LangChainAgentInvokeFinished",
                {
                    "session_id": request.session_id,
                    "raw_output_preview": str(ai_response.get("output", ""))[:120],
                },
            )
            ai_response_text = ai_response.get("output", "ì£„ì†¡í•´ìš”, ë‹µë³€ì„ ë§Œë“¤ì§€ ëª»í–ˆì–´ìš”.")

            fallback_override = None
            if "iteration limit" in ai_response_text.lower():
                fallback_override = await _build_recipe_fallback_response()
                _log_recipe_debug("FallbackTriggered", {"session_id": request.session_id})

            if fallback_override:
                ai_response_payload, display_text = fallback_override
            else:
                ai_response_payload, display_text = _normalize_agent_output(ai_response_text)

    if is_new_conversation:
        conversation = Conversation(
            session_id=request.session_id,
            user_id=current_user.user_id,
            all_chat="",
            sum_chat=conversation_summary,
            last_message_summarized_at=datetime.utcnow(),
        )
        db.add(conversation)

    new_turn = f"Human: {request.message}\nAI: {display_text}\n\n"
    conversation.all_chat = (conversation.all_chat or "") + new_turn
    conversation.last_message_timestamp = datetime.utcnow()

    db.add_all(
        [
            ChatHistory(
                user_id=current_user.user_id,
                session_id=request.session_id,
                message_type="human",
                content=request.message,
            ),
            ChatHistory(
                user_id=current_user.user_id,
                session_id=request.session_id,
                message_type="ai",
                content=display_text,
            ),
        ]
    )

    await db.commit()

    if not redis_client:
        background_tasks.add_task(
            chat_service.summarize_conversation_if_needed, request.session_id
        )

    return ChatMessageResponse(
        session_id=request.session_id,
        response=ai_response_payload,
        needs_tool_call=needs_tool_call_flag,
    )
